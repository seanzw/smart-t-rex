
%% bare_conf.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex
%%*************************************************************************

% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices can trigger bugs that do  ***
% *** not appear when using other class files.                            ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[conference]{IEEEtran}
\usepackage{blindtext, graphicx}
% Add the compsoc option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}

% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
% \usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
%   \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found as epslatex.ps or
% epslatex.pdf at: http://www.ctan.org/tex-archive/info/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex

\usepackage{hyperref}



% *** MATH PACKAGES ***
%
\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/





% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.

\usepackage{biblatex}
\bibliography{refs}

\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later 
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/



%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.





% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Artificial Intelligence for T-Rex Running}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Zhengrong Wang, Bisheng Huang, Kaiwen Huang, Aozhu Chen, Ning Xin}
\IEEEauthorblockA{Department of Computer Science\\
University of California, Los Angeles\\
\{seanzw, bhuang16, kaiwen1, achen28, nxin\}@ucla.edu}}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle


\begin{abstract}
%\boldmath
In this project, we present an artificial agent to play the game T-Rex Running based on reinforcement learning.
\end{abstract}
% IEEEtran.cls defaults to using nonbold math in the Abstract.
% This preserves the distinction between vectors and scalars. However,
% if the journal you are submitting to favors bold math in the abstract,
% then you can use LaTeX's standard command \boldmath at the very start
% of the abstract to achieve this. Many IEEE journals frown on math
% in the abstract anyway.

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Reinforcement learning, Q-learning
\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle


\section{Introduction}


% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command, the
% \label for the overall figure must come after \caption.
% \hfil must be used as a separator to get equal spacing.
% The subfigure.sty package works much the same way, except \subfigure is
% used instead of \subfloat.
%
% \begin{figure*}[!t]
% \centerline{\subfloat[Case I]\includegraphics[width=2.5in]{subfigcase1}%
% \label{fig_first_case}}
% \hfil
% \subfloat[Case II]{\includegraphics[width=2.5in]{subfigcase2}%
% \label{fig_second_case}}}
% \caption{Simulation results}
% \label{fig_sim}
% \end{figure*}

% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.


% An example of a floating table. Note that, for IEEE style tables, the 
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that IEEE does not put floats in the very first column - or typically
% anywhere on the first page for that matter. Also, in-text middle ("here")
% positioning is not used. Most IEEE journals use top floats exclusively.
% Note that, LaTeX2e, unlike IEEE journals, places footnotes above bottom
% floats. This can be corrected via the \fnbelowfloat command of the
% stfloats package.

\section{T-Rex Running Game}

\subsection{World}
A moving horizon with an increasing speed from 6 to 13.
Two types of obstacles: cactus and birds.
Cactus can have different size.
\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{img/coordinate}
\DeclareGraphicsExtensions.
\caption{Coordinate of TRex World}
\label{fig:coordinate}
\end{figure}


\subsection{Challenges}
\begin{enumerate}
    \item Speed of bird can have a positive or negative speed offset.
\end{enumerate}
\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{img/obstacles}
\DeclareGraphicsExtensions.
\caption{Different Obstacles In the Game}
\label{fig:obstacles}
\end{figure}


\section{Q-Learning}
A general introduction. States and actions. Reward.

\section{Perception}
Since we want to the TRex to learn to jump across the obstacles, we need to define what variables it can perceive during the game. Most of the features we defined in this section is related to TRex itself and only the first obstacle, as our little poor TRex cannot see through it.
\subsection{X Position}
The most important feature is the x position of the first obstacle. It measures the distance from the first obstacle to the TRex. With this feature, TRex should be able to learn the most basic strategy of jumping when the obstacle is approaching. Fig.~\ref{fig:features} shows an illustration of $x$.
\subsection{Width \& Height}
However, as mentioned above, the width and the height of obstacles varies. This makes the jumping position for different obstacles maybe different. Therefore, our TRex is capable of detecting the size of the first obstacle, including the width and the height. Fig.~\ref{fig:features} shows an illustration of $w$ and $h$.
\subsection{Relative Velocity}
Another thing that changes during the game is the running speed of the TRex. It gradually speeds up during the game and may need different strategy during high speed than low speed. It is reasonable to assume that the TRex can feel its own velocity to the ground. However, as mentioned above, the speed of pterodactyls can have an offset to the ground, if TRex can only feel its own absolute velocity to the ground, it cannot capture the information that a pterodactyl is approaching faster or slower than other normal cactus. Therefore, the TRex should be aware of the relative speed between itself and the first obstacle. Fig.~\ref{fig:features} shows an illustration of the relative velocity $v$.

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{img/features}
\DeclareGraphicsExtensions.
\caption{TRex's perception}
\label{fig:features}
\end{figure}

\section{Model}
\subsection{Q-Learning}
In this section, we will describe the process of Q-learning in our model. 

\subsubsection{Bucketing the perceptions to features}

First, we need to encode the environment, i.e. perceptions of the TRex, into several discrete states. Since the variables in the perception are floating point numbers, we use a certain number of buckets to discretize them. The bucketing process for each variable can be described as followed.

For the X position of the obstacle,
\begin{equation}
    \hat{x}=\frac{x}{CANVAS\_WIDTH} * BUCKET_X
    \label{eq:x_bucket}
\end{equation}

For the height of the obstacle,
\begin{equation}
    \hat{h}=\frac{h}{CANVAS\_HEIGHT} * BUCKET_H
    \label{eq:h_bucket}
\end{equation}

For the relative velocity,
\begin{equation}
    \hat{v}=\frac{v - MIN\_V + offset}{MAX\_V - MIN\_V + 1} * BUCKET_V
    \label{eq:v_bucket}
\end{equation}

$CANVAS\_WIDTH$ and $CANVAS\_HEIGHT$ represent the width and the height of the canvas, respectively. BUCKET denotes the bucket size for that variable. Empirically, ${BUCKET}_{X}$ = 20, ${BUCKET}_{{H}}$ = 10, ${BUCKET}_{{V}}$ = 10. $MAX\_V$ and $MIN\_V$ denote the maximal velocity and minimal velocity of the horizon, and their values are 13 and 6 respectively. $Offset$ is a variable denoting the speed offset of the obstacle. For an obstacle belong to the type of cactus, $offset$ = 0; for a pterodactyls-type obstacle, $offset$ can be either 0.8 or -0.8 with equal probability.

Notice that bucket size is a factor worth considering. A large bucket size will result in a larger state space, which will take more iterations to train, while a small bucket size will not be sufficient to represent the environment unambiguously. 

\subsubsection{Testing the efficiency of the perceptions}

In order to learn the amount of information needed to solve the game, we gradually add features to expand the state spaces. The combinations of features we tested in our experiment are listed as followed. The number is the bracket represents the number of all the possible states. Notice that there is an empty state representing no obstacle at sight.
\begin{enumerate}
    \item X Position 
    
    ($BUCKET_X + 1$)
    \item X Position + Height 
    
    ($BUCKET_X * BUCKET_H + 1$)
    \item X Position + Height + Velocity

    ($BUCKET_X * BUCKET_H * BUCKET_V + 1$)
\end{enumerate}

\subsubsection{Ignoring some states when updating the Q-table}

In the framework of Q-learning, the agent will constantly choose an action for each state. But in the TRex game, once the Trex jumps into the air, it cannot perform any other actions until it lands on the horizon. To simplify the Q-learning process in our model, Q-table will not be updated during this period. In other words, when the agent chooses the action of jumping, the next state will be the state when the TRex lands on the horizon or hits an obstacle, instead of a state in which TRex is jumping in the air.

\subsubsection{Reward}

For a state in which the TRex collided with an obstacle, the reward was set to -1000. When the TRex is running on the horizon, the reward is 0. When the TRex jumps over an obstacle and lands on the horizon, the reward is 1. The default behavior for the Q-learning agent is doing nothing, which means that if two actions have the same reward for the current state, the agent will choose to stay on the horizon instead of jumping.

\subsection{Deep-Q-Learning}
We also tried Deep-Q-Learning algorithm. We use a forward neural network to approximate the Q function. 

\subsubsection{Normalize Features}
First, we use the same equation as Eq.~\ref{eq:x_bucket}, Eq.~\ref{eq:h_bucket} and Eq.~\ref{eq:v_bucket} to normalize the data. Notice that for neural network the input can be a continuous value. Therefore, we do not have to bucketize the features to discrete values, and the value for each feature is within the range $[0, 1]$. For example, the X position of the first obstacle is normalized with
\begin{equation}
    \hat{x}=\frac{x}{CANVAS\_WIDTH}
\end{equation}

\subsubsection{Training Detail}
As mentioned above, the most challenging part for Deep-Q-Learning is that the network may not converge. Here we implement the algorithm from \cite{mnih2015humanlevel}. There are a few details we want to mention for training. 

First, the agent of Deep-Q-Learning does not make a decision for each frame. Instead, it only decides whether to jump or not every 6 frames. This is to make sure that neighboring samples used for training differ from each other and make the training process more stable. 

Another thing to notice is that as mentioned in the algorithm, we use an experience buffer and a separate network to compute the target value for the update. The target neural network is updated every 1000 iterations.

\subsubsection{Network Structure}
We use a simple 4 layer neural network. The first layer is the input layer. The second and third layer are both fully connected layer and each contains 64 neurons. Finally, there is a regression layer which outputs the estimated Q value for each state action tuple.

Notice that we have tried more complex network structure and input, e.g. CNN for pixel input, however, the whole experiment is carried out in the browser and the computation power is very limited. It takes more than 2 seconds for the browser to finish one back propagation and we have to focus on handcrafted feature with simple neural network structure rather than raw pixels.

\subsubsection{Reward}
We use a different reward than that for Q-Learning. If the TRex hits an obstacle and died, we give the agent -1 reward. If the TRex passes through an obstacle, either by jumping or doing nothing as the pterodactyl is too high, we give the agent 1 reward. Otherwise, the reward is 0.

\section{Implementation}
In this section, we talk more about our implementation.
\subsection{Framework}
We the code extracted from Chromium \cite{TRexGame} as our basic framework. Then we modify the code so that when updating each frame, an agent can make a decision of whether jumping or not. 

We introduce an interface for the communication between the engine and the agent as listed in Table~\ref{tab:api}. The most important API is act(), which takes in the engine instance and the reward of the previous decision. The agent will extract the current state from the engine and make a decision of whether jumping or not. If necessary, e.g. the agent is still learning how to play, it can use the reward and its decision history to train itself.

\begin{table}[!t]
% increase table row spacing, adjust to taste
\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
\caption{API of Agent}
\label{tab:api}
\centering
% Some packages, such as MDW tools, offer better commands for making tables
% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{l l l l}
\hline
API & Arguments & Returns & Description \\
\hline
act & Engine, Reward & Jump or Not & Make the decision, may train the agent.\\
\hline
save & / & Model & Return a serialized model to save.\\
\hline
load & Model & / & Load a model. \\
\hline
\end{tabular}
\end{table}

\subsection{Agents}
Given the API, we implement four agents listed as in Table~\ref{tab:agent}. Notice that the Human agent will always do nothing so that it will not interfere the human player. The Cheat agent employs a handcrafted AI which uses the information of speed, X position, and height of the first obstacle. It is used along with human player as the baseline.

\begin{table}[!t]
% increase table row spacing, adjust to taste
\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
\caption{Agent Implemented}
\label{tab:agent}
\centering
% Some packages, such as MDW tools, offer better commands for making tables
% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{l l}
\hline
Agent & Description \\
\hline
Human & Always do nothing so no interference to human player.\\
\hline
Cheat & A carefully handcrafted AI. \\
\hline
Q-Table & Use Q Table to learn the game. \\
\hline
Deep-Q-Net & Use neural network to learn the game. \\
\hline
\end{tabular}
\end{table}


\subsection{Front End Utility}
Fig.~\ref{fig:frontend} shows our front-end design and it supports the following functionality.

\begin{enumerate}
    \item Select Speed\\
    The user can change the simulation speed of the engine. Currently, the engine supports two level of speed: crazy and sober. In sober mode, frames are rendered at 60 FPS, while in crazy mode the engine renders as fast as possible. Notice that this is not the running speed of the TRex and the crazy mode should only be used for training an agent.
    \item Change Agent\\
    The user can select different agents from the menu. For some agents, e.g. Q-Table and Deep-Q-Net agent, there are multiple models can be used. Different models utilize different features like the relative speed of the TRex and so on.
    \item Save \& Load Model\\
    After a long time of training, the user can also save the trained model. It is also possible to load a pre-trained model and let the agent play directly.
    \item Save Scores\\
    The user can also save the history scores of the current agent into a csv file. It is useful to illustrate how the agent improves its skill as training goes on.
\end{enumerate}

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{img/ui}
\DeclareGraphicsExtensions.
\caption{The Front End Design}
\label{fig:frontend}
\end{figure}



\section{Result}

\subsection{Q-Learning}

\subsubsection{Experiment Setup}
    In our experiment, each agent first went through a training process. The number of iterations in the training process for each combination of features was chosen as 100000 empirically, during which the Q-table was updated after each iteration. After training, the performances of each agent were evaluated.
    
\subsubsection{Training process}
    During the training process, whenever the game was over, a game score would be recorded at the corresponding iteration. The relationship between the number of iterations and scores achieved was demonstrated in Fig.~\ref{fig:training_X} and Fig.~\ref{fig:training_X_H_S}, which corresponded to two set of features, respectively. Note that it will take more than one iteration for the game to end and generate a score. The better the agent performed, the more iterations were needed to generate a score. 
    
    It can be observed in Fig.~\ref{fig:training_X} that with only the position of the first obstacle, the game score fluctuated frequently during training. It once got as high as 3000 but later stabilized at around several hundred. This is a typical pattern when the information presented in the feature was not sufficient to solve the game. The key information that was missing in the feature was the velocity of the obstacle. Two scenarios in the game can have the same states but the velocity is different, which will confuse the agent. When the state spaces are small, there is no such solution or strategy that can pass all scenarios of obstacles. In this case, the strategy for the agent might not converge and the performance will fluctuate frequently.
    
    A relatively more robust learning curve can be observed in Fig.~\ref{fig:training_X_H_S}. With the information of relative velocity of the obstacle, the agents can learn how to act differently when the speed is different. At the same time, the score also grew more slowly due to an enlarged states space.


\subsubsection{Training Pattern}
    A typical training pattern for Q-learning agents can be described as followed. Initially, due to the default behavior of not jumping, the TRex will directly run into the obstacle. The crash state can be denoted as ${S}_{\textnormal{0}}$, and its previous state can be denoted as ${S}_{\textnormal{1}}$. When the collision happens, not jumping at ${S}_{\textnormal{1}}$ will be given a penalty, so that next time agent will choose to jump at ${S}_{\textnormal{1}}$. Now the agent is able to pass one obstacle, but it is jumping very close to obstacle. It will not change its strategy until two consecutive obstacles come up so that the agent finds it impossible to pass the second obstacle. Therefore, both jumping and not jumping at ${S}_{\textnormal{1}}$ are also given a penalty. The agent will try to avoid ${S}_{\textnormal{1}}$, and choose to jump at a previous state, say ${S}_{\textnormal{2}}$, and so on so forth.
    
    The difficult part of the game is when consecutive obstacles come up with a very small gap. Following this pattern, the Q-learning agent was able to learn the ideal strategy for this game: jump as early as possible for each obstacle.
    
\subsubsection{Q-learning Model evaluations}
    As shown in the result Table~\ref{tab:scores}, the score for Q-learning agents gradually increase with the introduction of more features. 
    
    With only the position of the obstacle, the score achieved is several hundred. After that it might be hard to deal with the increased speed. With the addition information of height, the agent can achieve a score of over one thousand. Relative velocity is a more important feature than height, as the score for the agent 'QL: Position + Velocity' is two times higher than the agent 'QL: Position + Height', which is also expected.
    
    The agent with all three perceptions already mastered the game and was able to achieve a performance that far exceeded human player and even the handcrafted Cheat AI, reaching as high as 590494.

\begin{table}[!t]
% increase table row spacing, adjust to taste
\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
\caption{Score achieved for Each Agent}
\label{tab:scores}
\centering
% Some packages, such as MDW tools, offer better commands for making tables
% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{l c c c c}
\hline
Agent & \# Iters & Max & Min & Average\\
\hline
Human & / & 4016 & 613 & 2031 \\
\hline
Keep Jumping & / & 21 & 21 & 21 \\
\hline
Random Action & / & 40 & 21 & 25 \\
\hline
Cheat & / & 62207 & 6058 & 22364 \\
\hline
QL: Position & 100000 & 945 & 361 & 580 \\
\hline
QL: Position + Height & 100000 & 1860 & 361 & 1163 \\
\hline
QL: Position + Velocity & 100000  & 8447 & 471 & 2075 \\
\hline
QL: Position + Height + Velocity & 100000  & 590494 & 717 & 159450 \\
\hline
DQL: Position & 100000 & 2033 & 745 & 1320 \\
\hline
DQL: Position + Height & 200000 & 180 & 32 & 105 \\
\hline
DQL: Position + Velocity & 200000  & 206 & 53 & 130 \\
\hline
DQL: Position + Height + Velocity & 200000  & 102 & 22 & 67 \\
\hline
\end{tabular}
\end{table}



\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{img/training_X}
\DeclareGraphicsExtensions.
\caption{Training with position}
\label{fig:training_X}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{img/training_X_H_S}
\DeclareGraphicsExtensions.
\caption{Training with position, height, velocity}
\label{fig:training_X_H_S}
\end{figure}

\subsection{Deep-Q-Learning}
Table~\ref{tab:scores} also shows the scores for Deep-Q-Learning models. As we expected, it is much more difficult to train neural network than traditional Q-Learning. The biggest challenge is that Deep-Q-Learning requires randomly taking actions during the training phase to explore the state space. However, with random actions, the game usually terminates with a score less than 100, and in this early phase the running speed of the TRex is very slow. As mentioned above, the speed of the TRex is very crucial for the TRex to determine when to jump.

Our experiment shows that with simple X position of the first obstacles, the neural network converges well and Fig.~\ref{fig:dql-x} shows the estimated Q value for two legal actions against the X position of the first obstacle. The x axis is the distance to the first obstacle. We can see that the agent is able to learn to not jump when the obstacle is far away (as the Q value of not jumping is higher than jumping) and start jumping when it comes close. 

For other Deep-Q-Learning models, additional features do not improve their performance. We think the current network structure is too simple to handle more features. However, the computation of the browser makes it not possible to train more complicate network. For example, we tried the 6 layers' CNN model introduced in \cite{mnih2015humanlevel}, and the back propagation for one mini-batch with 32 samples along takes more than 2 seconds. Also, complicate network requires more iteration to train. In \cite{mnih2015humanlevel} they used more than 35 days of gaming experience to train the model, which is impossible for our own PC.

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{img/DQL-X-response}
\DeclareGraphicsExtensions.
\caption{Q Value of DQL-X position}
\label{fig:dql-x}
\end{figure}

\section{Conclusion}
As discussed in the training pattern section of Q-learning, the Q-learning agent was able to learn to jump as early as possible for each obstacle, allowing for more space for the next obstacle. With the position, height, and relative velocity of the first obstacle, the agent can learn the essences of the game and was able to achieve a performance that far exceeded human players. It is demonstrated again that reinforcement learning, and more specifically Q-learning, is very promising in training artificial agents in the field of game playing. 

As for Deep-Q-Learning, we implemented the algorithm of DQN and trained it with different features. However, due to the limited computation power of the browser, it is not possible to use very complicate neural network, and the simplest model with only the X position of the first obstacle achieves the best result among all the Deep-Q-Learning models we have tried, but is still not as good as models from Q-Learning. We think that a more sophisticated network may be able to utilize additional features and performs better. We can try to export the game to other native platforms, e.g. Python with tensorflow as the backend to enable the usage of more complicated network structure and speed up the training phase. 

You can find all the implementation at \url{https://github.com/seanzw/smart-t-rex}. There is also a runnable website at \url{https://seanzw.github.io/smart-t-rex/}.


% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


% use section* for acknowledgement
% \section*{Acknowledgment}
% The authors would like to thank...


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
% \begin{thebibliography}{1}

% \bibitem{IEEEhowto:kopka}
% H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%   0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

% \end{thebibliography}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{biography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:
\printbibliography

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{picture}}]{John Doe}
% \blindtext
% \end{IEEEbiography}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}


% that's all folks
\end{document}